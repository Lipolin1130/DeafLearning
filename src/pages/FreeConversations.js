import React, { useState, useRef } from "react";
import { Link } from "react-router-dom";
import {
  FaMicrophone,
  FaArrowLeft,
  FaCamera,
  FaPhone,
  FaBook,
} from "react-icons/fa";
import "./FreeConversations.css";

const FreeConversations = () => {
  const [messages, setMessages] = useState([]);
  const [recording, setRecording] = useState(false);

  // ç”¨æ–¼éŒ„éŸ³
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);

  // å¾Œç«¯ API URL (è«‹ä¾ç…§å¯¦éš›éƒ¨ç½²èª¿æ•´)
  const BASE_URL = "http://140.134.25.53:8081/api";

  // é–‹å§‹ / åœæ­¢éŒ„éŸ³
  const handleRecord = async () => {
    if (!recording) {
      setRecording(true);
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const mediaRecorder = new MediaRecorder(stream);
        mediaRecorderRef.current = mediaRecorder;
        audioChunksRef.current = [];

        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunksRef.current.push(event.data);
          }
        };

        mediaRecorder.onstop = async () => {
          const audioBlob = new Blob(audioChunksRef.current, { type: "audio/wav" });
          const audioUrl = URL.createObjectURL(audioBlob);

          // 1. åœ¨å‰ç«¯é¡¯ç¤ºä½¿ç”¨è€…å‰›éŒ„å¥½çš„èªéŸ³è¨Šæ¯ (type: 'user')
          setMessages((prev) => [
            ...prev,
            {
              type: "user",
              audio: audioUrl,
            },
          ]);

          // 2. èªéŸ³è½‰æ–‡å­—ï¼šå‘¼å«å¾Œç«¯ /speech_to_text/ API
          const sttText = await convertSpeechToText(audioBlob);

          // 3. AI ç”Ÿæˆå›æ‡‰ (Placeholder)
          const aiText = await getAiResponse(sttText);

          // 4. å‘¼å«æ–‡å­—è½‰èªéŸ³ APIï¼Œå–å¾— AI çš„èªéŸ³å›è¦†
          const aiAudioUrl = await getTtsAudio(aiText);

          // 5. åœ¨å‰ç«¯é¡¯ç¤º AI çš„èªéŸ³èˆ‡æ–‡å­—è¨Šæ¯ (type: 'ai')
          setMessages((prev) => [
            ...prev,
            {
              type: "ai",
              audio: aiAudioUrl,
              text: aiText,
            },
          ]);

          // 6. å°‡æœ¬æ¬¡å°è©±è¨˜éŒ„å­˜å…¥ localStorage ä»¥ä¾¿ ReviewConversations.js è®€å–
          const newRecord = {
            date: new Date().toLocaleString(),
            content: `ä½¿ç”¨è€…ï¼š${sttText}\nAIï¼š${aiText}`,
          };

          // è®€å–ç¾æœ‰çš„å°è©±ç´€éŒ„ï¼ˆè‹¥ç„¡å‰‡å»ºç«‹ç©ºé™£åˆ—ï¼‰
          const stored = localStorage.getItem("conversations");
          const existingConversations = stored ? JSON.parse(stored) : [];
          existingConversations.push(newRecord);
          localStorage.setItem("conversations", JSON.stringify(existingConversations));
        };

        mediaRecorder.start();
      } catch (error) {
        console.error("ç„¡æ³•éŒ„éŸ³ï¼š", error);
        setRecording(false);
      }
    } else {
      setRecording(false);
      mediaRecorderRef.current?.stop();
    }
  };

  // èªéŸ³è½‰æ–‡å­—ï¼šå‘¼å«å¾Œç«¯ /speech_to_text/ API
  const convertSpeechToText = async (audioBlob) => {
    const formData = new FormData();
    formData.append("audio", audioBlob, "recording.wav");

    try {
      const response = await fetch(`${BASE_URL}/speech_to_text/`, {
        method: "POST",
        body: formData,
      });
      if (!response.ok) {
        throw new Error(`STT API éŒ¯èª¤: ${response.status}`);
      }
      const data = await response.json();
      // å‡è¨­å¾Œç«¯å›å‚³æ ¼å¼: { text: "è¾¨è­˜å¾Œçš„æ–‡å­—" }
      return data.text || "ç„¡æ³•è¾¨è­˜èªéŸ³";
    } catch (error) {
      console.error("convertSpeechToText error:", error);
      return "èªéŸ³è¾¨è­˜å¤±æ•—";
    }
  };

  // AI ç”Ÿæˆå›æ‡‰ (Placeholder)ï¼šæœªä¾†å¯æ•´åˆ GPT æˆ–å…¶ä»– NLP æ¨¡å‹
  const getAiResponse = async (userText) => {
    return `ä½ å‰›æ‰èªªçš„æ˜¯ï¼š${userText}`;
  };

  // æ–‡å­—è½‰èªéŸ³ï¼šå‘¼å«å¾Œç«¯ /generate/tts/ APIï¼Œå›å‚³ wav æª”æ¡ˆ
  const getTtsAudio = async (text) => {
    try {
      const response = await fetch(
        `${BASE_URL}/generate/tts/?text=${encodeURIComponent(text)}`
      );
      if (!response.ok) {
        throw new Error(`TTS API éŒ¯èª¤: ${response.status}`);
      }
      const arrayBuffer = await response.arrayBuffer();
      const audioBlob = new Blob([arrayBuffer], { type: "audio/wav" });
      return URL.createObjectURL(audioBlob);
    } catch (error) {
      console.error("getTtsAudio error:", error);
      return "";
    }
  };

  return (
    <div className="chat-container">
      {/* ä¸Šæ–¹æ¨™é¡Œå€åŸŸ */}
      <div className="every-title-area">
        <img
          src="/images/heart-hand.png"
          alt="æ‰‹èªæ„›å¿ƒ"
          className="every-heart-hand"
        />
        <h1>ç”Ÿè² â€” è‡ªç”±å°è©±</h1>
      </div>

      {/* èŠå¤©æ¡† */}
      <div className="chat-box">
        <Link to="/dialogue" className="back-button">
          <FaArrowLeft size={24} />
        </Link>
        <h2 className="chat-title">AI å°å¸«</h2>

        {/* è¨Šæ¯åˆ—è¡¨ */}
        <div className="chat-messages">
          {messages.length === 0 ? (
            <div className="empty-message">è«‹é»æ“ŠéŒ„éŸ³éµé–‹å§‹å°è©±</div>
          ) : (
            messages.map((msg, index) => (
              <div key={index} className={`message ${msg.type}`}>
                <span className="avatar">{msg.type === "ai" ? "ğŸ¤–" : "ğŸ˜Š"}</span>
                <audio controls className="audio-player">
                  <source src={msg.audio} type="audio/wav" />
                  Your browser does not support the audio element.
                </audio>
                {/* æ›¸æœ¬åœ–ç¤ºï¼šé¡¯ç¤º AI å›è¦†æ–‡å­—å…§å®¹ */}
                {msg.type === "ai" && msg.text && (
                  <button
                    className="book-icon"
                    onClick={() => alert(`AI å›è¦†æ–‡å­—ï¼š${msg.text}`)}
                  >
                    <FaBook size={20} />
                  </button>
                )}
              </div>
            ))
          )}
        </div>

        {/* åº•éƒ¨åŠŸèƒ½æŒ‰éˆ• */}
        <div className="chat-controls">
          <button className="icon-button">
            {/* é€™è£¡å¯ä»¥æ”¾ icon */}
          </button>
          <button onClick={handleRecord} className="record-button">
            {recording ? "ã€‚ã€‚ã€‚" : <FaMicrophone size={24} />}
          </button>
          <button className="icon-button">
            {/* é€™è£¡å¯ä»¥æ”¾ icon */}
          </button>
        </div>
      </div>

      {/* å›ä¸Šä¸€é çš„æŒ‰éˆ• */}
      <Link to="/dialogue" className="go-back-button">
        å›ä¸Šä¸€é 
      </Link>
    </div>
  );
};

export default FreeConversations;
