import React, { useState, useRef } from "react";
import { Link } from "react-router-dom";
import { FaMicrophone, FaArrowLeft, FaCamera, FaPhone, FaBook, FaVolumeUp } from "react-icons/fa";
import "./FreeConversations.css";

const FreeConversations = () => {
  const [messages, setMessages] = useState([]);
  const [recording, setRecording] = useState(false);
  const mediaRecorderRef = useRef(null);
  const audioChunks = useRef([]);
  const audioRefs = useRef([]);
  
  const handleRecord = async () => {
    if (!recording) {
      setRecording(true);
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunks.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks.current, { type: "audio/wav" });
        const audioUrl = URL.createObjectURL(audioBlob);
        setMessages((prev) => [...prev, { type: "user", audio: audioUrl }]);

        const text = await convertSpeechToText(audioBlob);
        const aiReply = await getAiResponse(text);

        setMessages((prev) => [...prev, { type: "ai", audio: aiReply.audio, text: aiReply.text }]);
      };

      mediaRecorder.start();
    } else {
      setRecording(false);
      mediaRecorderRef.current?.stop();
    }
  };

  const convertSpeechToText = async (audioBlob) => {
    return "ä½ å¥½ï¼Œé€™æ˜¯è½‰æ›çš„æ–‡æœ¬å…§å®¹";
  };

  const getAiResponse = async (text) => {
    return {
      text: "é€™æ˜¯ä¸€å€‹ AI ç”Ÿæˆçš„å›æ‡‰ï¼",
      audio: "path-to-ai-generated-audio.mp3",
    };
  };

  const adjustVolume = (index, event) => {
    if (audioRefs.current[index]) {
      audioRefs.current[index].volume = event.target.value;
    }
  };

  return (
    <div className="chat-container">
      <div className="every-title-area">
        <img
          src="/images/heart-hand.png"
          alt="æ‰‹èªæ„›å¿ƒ"
          className="every-heart-hand"
        />
        <h1>ç”Ÿè² â€” è‡ªç”±å°è©±</h1>
      </div>
      <div className="chat-box">
        <Link to="/dialogue" className="back-button">
          <FaArrowLeft size={24} />
        </Link>
        <h2 className="chat-title">AI å°å¸«</h2>
        <div className="chat-messages">
          {messages.map((msg, index) => (
            <div key={index} className={`message ${msg.type}`}>
              <span className="avatar">{msg.type === "ai" ? "ğŸ¤–" : "ğŸ˜Š"}</span>
              <audio controls className="audio-player" ref={(el) => (audioRefs.current[index] = el)}>
                <source src={msg.audio} type="audio/mp3" />
                Your browser does not support the audio element.
              </audio>
              <div className="volume-control">
                <FaVolumeUp />
                <input
                  type="range"
                  min="0"
                  max="1"
                  step="0.1"
                  onChange={(e) => adjustVolume(index, e)}
                />
              </div>
              {msg.type === "ai" && msg.text && (
                <button className="book-icon" onClick={() => alert(msg.text)}>
                  <FaBook size={20} />
                </button>
              )}
            </div>
          ))}
        </div>
        <div className="chat-controls">
          <button className="icon-button">
            <FaCamera size={24} />
          </button>
          <button onClick={handleRecord} className="record-button">
            {recording ? "åœæ­¢" : <FaMicrophone size={24} />}
          </button>
          <button className="icon-button">
            <FaPhone size={24} />
          </button>
        </div>
      </div>
      <Link to="/dialogue" className="go-back-button">å›ä¸Šä¸€é </Link>
    </div>
  );
};

export default FreeConversations;
